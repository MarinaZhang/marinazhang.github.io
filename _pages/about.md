---
layout: about
title: Home
permalink: /
subtitle: <a href='https://marinazhang.github.io/assets/pdf/cv.pdf'>CV</a> /  <a href='https://www.linkedin.com/in/marina-zhang'>LinkedIn</a> / <a href='https://scholar.google.com/citations?user=V9ehnpwAAAAJ&hl=en'>Google Scholar</a> / <a href='https://github.com/MarinaZhang'>GitHub</a>

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  address:

news: True  # includes a list of news items
latest_posts: false  # includes a list of the newest posts
selected_papers: False # includes a list of papers marked as "selected={true}"
social: false  # includes social icons at the bottom of the page
---
Hello! I am a software engineer on Google's [Security & Anti-Abuse Research Team](https://research.google/teams/security-privacy-abuse/), led by [Elie Bursztein](https://elie.net/). My research interests lie at the intersection of AI and security.

At Google, my research is primarily focused on building natural language processing (NLP) models and text embeddings that are secure, efficient, and robust against adversarial attacks. I'm also interested in designing novel, machine learning-based solutions to tackle important security challenges such as phishing, malware and abuse detection.

Prior to joining Google, I graduated from MIT in 2021 with a double major in Computer Science and Engineering & Mathematics.

<!-- 
My research is primarily focused on building adversarially robust deep learning models and developing novel machine learning-based solutions to security problems. Several projects I’ve worked on over the last few years include: building robust and scalable text embeddings using deep similarity learning, clustering and classifying spam/phishing/malware campaigns across Google products, malicious URL detection for end-to-end encrypted environments, and side channel attacks on cryptographic hardware. More recently, I’ve been interested in investigating the security vulnerabilities and trustworthiness of LLMs, as well as the potential applications of LLMs to long-standing security and privacy problems. -->
<!-- 
Email: <a href='mailto:marinazh@google.com'>marinazh@google.com</a>  -->

